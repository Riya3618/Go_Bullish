{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StockShort.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V75SgSU1TVt",
        "outputId": "57427656-8a9a-4401-e6a8-9bf7c19c094e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install tensorflow \n",
        "!pip3 install yahoo_fin \n",
        "!pip3 install requests_html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Collecting yahoo_fin\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/5c/6bf0c0147cc94d643e2a2413d0a9b27967e964ee99f88f26db93a0b963b8/yahoo_fin-0.8.6-py3-none-any.whl\n",
            "Installing collected packages: yahoo-fin\n",
            "Successfully installed yahoo-fin-0.8.6\n",
            "Collecting requests_html\n",
            "  Downloading https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl\n",
            "Collecting pyquery\n",
            "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
            "Collecting w3lib\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n",
            "Collecting fake-useragent\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/79/af647635d6968e2deb57a208d309f6069d31cb138066d7e821e575112a80/fake-useragent-0.1.11.tar.gz\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from requests_html) (0.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from requests_html) (2.23.0)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/4b/3c2aabdd1b91fa52aa9de6cde33b488b0592b4d48efb0ad9efbf71c49f5b/pyppeteer-0.2.2-py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 9.9MB/s \n",
            "\u001b[?25hCollecting parse\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/49/85f19d9ff908817b864deebf7f68211f9a6fc0b48746d372d970f60d01f5/parse-1.18.0.tar.gz\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.6/dist-packages (from pyquery->requests_html) (4.2.6)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from w3lib->requests_html) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->requests_html) (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (1.24.3)\n",
            "Collecting websockets<9.0,>=8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.6MB/s \n",
            "\u001b[?25hCollecting appdirs<2.0.0,>=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting tqdm<5.0.0,>=4.42.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/0e/ea53a3d6f1eb2cc31162c9ae89555cc26a3986e5559781f0b0df75aea5cf/tqdm-4.50.0-py2.py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[?25hCollecting pyee<8.0.0,>=7.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/64/f3/90db6276dbc6cb1defa558251acc73c8e436ca8e1e2b38ec75786278de7c/pyee-7.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: fake-useragent, parse\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-cp36-none-any.whl size=13485 sha256=79549838b63a153919720982fbc0615fceb34ad1e9d83f8bf1eff114ef6a4755\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/63/09/d1dc15179f175357d3f5c00cbffbac37f9e8690d80545143ff\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.18.0-cp36-none-any.whl size=24133 sha256=0768cfaee889695127f6674fd7c5a7f367f76030bb391907d91d2dc198ad2840\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/53/09/869ca5781ede342254ffac09ca99461b008c3e5f8dd079b0c0\n",
            "Successfully built fake-useragent parse\n",
            "\u001b[31mERROR: pyppeteer 0.2.2 has requirement urllib3<2.0.0,>=1.25.8, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cssselect, pyquery, w3lib, fake-useragent, websockets, appdirs, tqdm, pyee, pyppeteer, parse, requests-html\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed appdirs-1.4.4 cssselect-1.1.0 fake-useragent-0.1.11 parse-1.18.0 pyee-7.0.4 pyppeteer-0.2.2 pyquery-1.4.1 requests-html-0.10.0 tqdm-4.50.0 w3lib-1.22.0 websockets-8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Qp4ekcNUpb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import csv\n",
        "import pandas_datareader.data as web\n",
        "import pandas_datareader as pdr\n",
        "from pandas_datareader import data, wb\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.core.common.is_list_like = pd.api.types.is_list_like #For solving import pandas_datareader issue\n",
        "import os\n",
        "import random\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import urllib.request\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhS568hr6yDL",
        "outputId": "55bb94d9-9310-41ff-c83d-086f294fb91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "wiki_url = 'https://en.wikipedia.org/wiki/NIFTY_50'    \n",
        "html1=urlopen(wiki_url)\n",
        "soup = BeautifulSoup(html1, 'html.parser')\n",
        "nse50data1=\"\"\n",
        "\n",
        "table = soup.find_all('table', class_=\"wikitable\")[0] \n",
        "\n",
        "for record in table.findAll('tr'):\n",
        "    nse50data=\"\"\n",
        "    for data in record.findAll('td'):\n",
        "        nse50data=nse50data+\",\"+data.text\n",
        "    nse50data1=nse50data1+\"\\n\"+nse50data[1:]\n",
        "\n",
        "print(nse50data1)\n",
        "f= open(\"nse50.txt\",\"w+\")\n",
        "\n",
        "f.write(nse50data1)\n",
        "f.close()\n",
        "head = []\n",
        "for th in table.find(\"tr\").find_all(\"th\"):\n",
        "        head.append(th.text.strip())\n",
        "rows_l = []\n",
        "for tr in table.find_all(\"tr\")[1:]:\n",
        "        cell_l = []\n",
        "        # grab all td tags in this table row\n",
        "        tds = tr.find_all(\"td\")\n",
        "        if len(tds) == 0:\n",
        "           \n",
        "            ths = tr.find_all(\"th\")\n",
        "            for th in ths:\n",
        "                cell_l.append(th.text.strip())\n",
        "        else:\n",
        "            # use regular td tags\n",
        "            for td in tds:\n",
        "                cell_l.append(td.text.strip())\n",
        "        rows_l.append(cell_l)\n",
        "d=pd.DataFrame(rows_l, columns=head).to_csv(f\"table.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Adani Ports,ADANIPORTS.NS,Infrastructure\n",
            "\n",
            "Asian Paints,ASIANPAINT.NS,Consumer Goods\n",
            "\n",
            "Axis Bank,AXISBANK.NS,Banking\n",
            "\n",
            "Bajaj Auto,BAJAJ-AUTO.NS,Automobile\n",
            "\n",
            "Bajaj Finance,BAJFINANCE.NS,Financial Services\n",
            "\n",
            "Bajaj Finserv,BAJAJFINSV.NS,Financial Services\n",
            "\n",
            "Bharti Airtel,BHARTIARTL.NS,Telecommunication\n",
            "\n",
            "Bharat Petroleum,BPCL.NS,Energy - Oil & Gas\n",
            "\n",
            "Britannia Industries,BRITANNIA.NS,Consumer Goods\n",
            "\n",
            "Cipla,CIPLA.NS,Pharmaceuticals\n",
            "\n",
            "Coal India,COALINDIA.NS,Energy & Mining\n",
            "\n",
            "Divi's Laboratories,DIVISLAB.NS,Pharmaceuticals\n",
            "\n",
            "Dr. Reddy's Laboratories,DRREDDY.NS,Pharmaceuticals\n",
            "\n",
            "Eicher Motors,EICHERMOT.NS,Automobile\n",
            "\n",
            "GAIL,GAIL.NS,Energy - Oil & Gas\n",
            "\n",
            "Grasim Industries,GRASIM.NS,Cement\n",
            "\n",
            "HCL Technologies,HCLTECH.NS,Information Technology\n",
            "\n",
            "HDFC,HDFC.NS,Financial Services\n",
            "\n",
            "HDFC Bank,HDFCBANK.NS,Banking\n",
            "\n",
            "HDFC Life,HDFCLIFE.NS,Insurance\n",
            "\n",
            "Hero MotoCorp,HEROMOTOCO.NS,Automobile\n",
            "\n",
            "Hindalco Industries,HINDALCO.NS,Metals\n",
            "\n",
            "Hindustan Unilever,HINDUNILVR.NS,Consumer Goods\n",
            "\n",
            "ICICI Bank,ICICIBANK.NS,Banking\n",
            "\n",
            "IndusInd Bank,INDUSINDBK.NS,Banking\n",
            "\n",
            "Infosys,INFY.NS,Information Technology\n",
            "\n",
            "Indian Oil Corporation,IOC.NS,Energy - Oil & Gas\n",
            "\n",
            "ITC Limited,ITC.NS,Consumer Goods\n",
            "\n",
            "JSW Steel,JSWSTEEL.NS,Metals\n",
            "\n",
            "Kotak Mahindra Bank,KOTAKBANK.NS,Banking\n",
            "\n",
            "Larsen & Toubro,LT.NS,Construction\n",
            "\n",
            "Mahindra & Mahindra,M&M.NS,Automobile\n",
            "\n",
            "Maruti Suzuki,MARUTI.NS,Automobile\n",
            "\n",
            "Nestlé India,NESTLEIND.NS,Consumer Goods\n",
            "\n",
            "NTPC,NTPC.NS,Energy - Power\n",
            "\n",
            "Oil and Natural Gas Corporation,ONGC.NS,Energy - Oil & Gas\n",
            "\n",
            "Power Grid Corporation of India,POWERGRID.NS,Energy - Power\n",
            "\n",
            "Reliance Industries,RELIANCE.NS,Energy - Oil & Gas\n",
            "\n",
            "State Bank of India,SBIN.NS,Banking\n",
            "\n",
            "SBI Life Insurance Company,SBILIFE.NS,Insurance\n",
            "\n",
            "Shree Cements,SHREECEM.NS,Cement\n",
            "\n",
            "Sun Pharmaceutical,SUNPHARMA.NS,Pharmaceuticals\n",
            "\n",
            "Tata Motors,TATAMOTORS.NS,Automobile\n",
            "\n",
            "Tata Steel,TATASTEEL.NS,Metals\n",
            "\n",
            "Tata Consultancy Services,TCS.NS,Information Technology\n",
            "\n",
            "Tech Mahindra,TECHM.NS,Information Technology\n",
            "\n",
            "Titan Company,TITAN.NS,Consumer Goods\n",
            "\n",
            "UltraTech Cement,ULTRACEMCO.NS,Cement\n",
            "\n",
            "United Phosphorus Limited,UPL.NS,Chemicals\n",
            "\n",
            "Wipro,WIPRO.NS,Information Technology\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5sR1sqSK4RE",
        "outputId": "1bf79bcf-5fa6-4c4b-b479-e316f94eda12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "# Import list of stock names from NSE website\n",
        "with requests.Session() as sen:\n",
        "    down= sen.get('https://www1.nseindia.com/products/content/sec_bhavdata_full.csv')\n",
        "    decoded= down.content.decode('utf-8')\n",
        "    csv_read = csv.reader(decoded.splitlines(), delimiter=',')\n",
        "    df = pd.DataFrame(list(csv_read))\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SYMBOL</td>\n",
              "      <td>SERIES</td>\n",
              "      <td>DATE1</td>\n",
              "      <td>PREV_CLOSE</td>\n",
              "      <td>OPEN_PRICE</td>\n",
              "      <td>HIGH_PRICE</td>\n",
              "      <td>LOW_PRICE</td>\n",
              "      <td>LAST_PRICE</td>\n",
              "      <td>CLOSE_PRICE</td>\n",
              "      <td>AVG_PRICE</td>\n",
              "      <td>TTL_TRD_QNTY</td>\n",
              "      <td>TURNOVER_LACS</td>\n",
              "      <td>NO_OF_TRADES</td>\n",
              "      <td>DELIV_QTY</td>\n",
              "      <td>DELIV_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20MICRONS</td>\n",
              "      <td>EQ</td>\n",
              "      <td>29-Sep-2020</td>\n",
              "      <td>29.10</td>\n",
              "      <td>29.10</td>\n",
              "      <td>29.70</td>\n",
              "      <td>28.35</td>\n",
              "      <td>29.15</td>\n",
              "      <td>28.60</td>\n",
              "      <td>28.83</td>\n",
              "      <td>17085</td>\n",
              "      <td>4.93</td>\n",
              "      <td>289</td>\n",
              "      <td>9484</td>\n",
              "      <td>55.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21STCENMGM</td>\n",
              "      <td>EQ</td>\n",
              "      <td>29-Sep-2020</td>\n",
              "      <td>10.25</td>\n",
              "      <td>10.25</td>\n",
              "      <td>10.35</td>\n",
              "      <td>10.05</td>\n",
              "      <td>10.05</td>\n",
              "      <td>10.05</td>\n",
              "      <td>10.12</td>\n",
              "      <td>1050</td>\n",
              "      <td>0.11</td>\n",
              "      <td>16</td>\n",
              "      <td>1050</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3IINFOTECH</td>\n",
              "      <td>EQ</td>\n",
              "      <td>29-Sep-2020</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.05</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.12</td>\n",
              "      <td>2098201</td>\n",
              "      <td>65.53</td>\n",
              "      <td>1083</td>\n",
              "      <td>1216528</td>\n",
              "      <td>57.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3MINDIA</td>\n",
              "      <td>EQ</td>\n",
              "      <td>29-Sep-2020</td>\n",
              "      <td>18361.85</td>\n",
              "      <td>18499.95</td>\n",
              "      <td>18550.00</td>\n",
              "      <td>18100.00</td>\n",
              "      <td>18384.00</td>\n",
              "      <td>18399.70</td>\n",
              "      <td>18344.78</td>\n",
              "      <td>3576</td>\n",
              "      <td>656.01</td>\n",
              "      <td>1657</td>\n",
              "      <td>1145</td>\n",
              "      <td>32.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0        1             2   ...             12          13          14\n",
              "0      SYMBOL   SERIES         DATE1  ...   NO_OF_TRADES   DELIV_QTY   DELIV_PER\n",
              "1   20MICRONS       EQ   29-Sep-2020  ...            289        9484       55.51\n",
              "2  21STCENMGM       EQ   29-Sep-2020  ...             16        1050      100.00\n",
              "3  3IINFOTECH       EQ   29-Sep-2020  ...           1083     1216528       57.98\n",
              "4     3MINDIA       EQ   29-Sep-2020  ...           1657        1145       32.02\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPJaD2dE7Csh"
      },
      "source": [
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMxVn2uw7GD9",
        "outputId": "10b70d93-8993-446b-8ee1-44f2783860b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "print(\"(CHOOSE THE TICKER FROM DATAFRAME MENTIONED ABOVE)\")\n",
        "print(\"\\nEnter the ticker\")\n",
        "stock_in=input()\n",
        "def load_data(tick=stock_in, n_step=50, scale=True, shuffle=True, lookup_step=1, \n",
        "                test_size=0.2, feat_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    \"\"\"\n",
        "    Variable description\n",
        "    Loads data from Yahoo Finance source and scaling, shuffling, normalizing and splitting.\n",
        "    Parameters:\n",
        "        tick (str/pd.DataFrame): the ticker you want to load\n",
        "        n_step(int): the historical sequence length (i.e window size) used to predict, default is 50\n",
        "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
        "        shuffle (bool): whether to shuffle the data, default is True\n",
        "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
        "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
        "        feat_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
        "    \"\"\"\n",
        "    # see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(tick, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(tick)\n",
        "    elif isinstance(tick, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = tick\n",
        "    else:\n",
        "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
        "    # this will contain all the elements we want to return from this function\n",
        "    res = {}\n",
        "    # we will also return the original dataframe itself\n",
        "    res['df'] = df.copy()\n",
        "    # make sure that the passed feat_columns exist in the dataframe\n",
        "    for col in feat_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "    if scale:\n",
        "        scaler_column = {}\n",
        "        # scale the data (prices) from 0 to 1\n",
        "        for column in feat_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            scaler_column[column] = scaler\n",
        "        # add the MinMaxScaler instances to the res returned\n",
        "        res[\"scaler_column\"] = scaler_column\n",
        "    # add the target column (label) by shifting by `lookup_step`\n",
        "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
        "  \n",
        "    seq_last = np.array(df[feat_columns].tail(lookup_step))\n",
        "  \n",
        "    df.dropna(inplace=True)\n",
        "    data_seq = []\n",
        "    sequences = deque(maxlen=n_step)\n",
        "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_step:\n",
        "            data_seq.append([np.array(sequences), target])\n",
        "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
        "\n",
        "    # this seq_last will be used to predict future stock prices not available in the dataset\n",
        "    seq_last = list(sequences) + list(seq_last)\n",
        "    seq_last = np.array(seq_last)\n",
        "    \n",
        "    res['seq_last'] = seq_last\n",
        "    # construct the X's and y's\n",
        "    X, y = [], []\n",
        "    for seq, target in data_seq:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    \n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # reshape X to fit the neural network\n",
        "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
        "    # split the dataset\n",
        "    res[\"X_train\"], res[\"X_test\"], res[\"y_train\"], res[\"y_test\"] = train_test_split(X, y, \n",
        "   \n",
        "    return res"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(CHOOSE THE TICKER FROM DATAFRAME MENTIONED ABOVE)\n",
            "\n",
            "Enter the ticker\n",
            "GAIL.NS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CemfTsKK0jJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgP9q_Cwidmo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}