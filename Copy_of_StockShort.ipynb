{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of  StockShort.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V75SgSU1TVt",
        "outputId": "f39765b7-6a3a-489c-822f-842c9e4e0ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install tensorflow \n",
        "!pip3 install yahoo_fin \n",
        "!pip3 install requests_html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Collecting yahoo_fin\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/5c/6bf0c0147cc94d643e2a2413d0a9b27967e964ee99f88f26db93a0b963b8/yahoo_fin-0.8.6-py3-none-any.whl\n",
            "Installing collected packages: yahoo-fin\n",
            "Successfully installed yahoo-fin-0.8.6\n",
            "Collecting requests_html\n",
            "  Downloading https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl\n",
            "Collecting pyquery\n",
            "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
            "Collecting fake-useragent\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/79/af647635d6968e2deb57a208d309f6069d31cb138066d7e821e575112a80/fake-useragent-0.1.11.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from requests_html) (2.23.0)\n",
            "Collecting parse\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/49/85f19d9ff908817b864deebf7f68211f9a6fc0b48746d372d970f60d01f5/parse-1.18.0.tar.gz\n",
            "Collecting w3lib\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from requests_html) (0.0.1)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/4b/3c2aabdd1b91fa52aa9de6cde33b488b0592b4d48efb0ad9efbf71c49f5b/pyppeteer-0.2.2-py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 7.0MB/s \n",
            "\u001b[?25hCollecting cssselect>0.7.9\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.6/dist-packages (from pyquery->requests_html) (4.2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (1.24.3)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from w3lib->requests_html) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->requests_html) (4.6.3)\n",
            "Collecting websockets<9.0,>=8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.0MB/s \n",
            "\u001b[?25hCollecting tqdm<5.0.0,>=4.42.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/0e/ea53a3d6f1eb2cc31162c9ae89555cc26a3986e5559781f0b0df75aea5cf/tqdm-4.50.0-py2.py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25hCollecting pyee<8.0.0,>=7.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/64/f3/90db6276dbc6cb1defa558251acc73c8e436ca8e1e2b38ec75786278de7c/pyee-7.0.4-py2.py3-none-any.whl\n",
            "Collecting appdirs<2.0.0,>=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: fake-useragent, parse\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-cp36-none-any.whl size=13485 sha256=540731078ea69d5eb18e04bee991535d6b24bdf9db8c1d62e6f071a38e2cee8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/63/09/d1dc15179f175357d3f5c00cbffbac37f9e8690d80545143ff\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.18.0-cp36-none-any.whl size=24133 sha256=6ddcdf2e85f7489d3dae281235c0da0c474701ebbe3c028c7cc822bba97a239b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/53/09/869ca5781ede342254ffac09ca99461b008c3e5f8dd079b0c0\n",
            "Successfully built fake-useragent parse\n",
            "\u001b[31mERROR: pyppeteer 0.2.2 has requirement urllib3<2.0.0,>=1.25.8, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cssselect, pyquery, fake-useragent, parse, w3lib, websockets, tqdm, pyee, appdirs, pyppeteer, requests-html\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed appdirs-1.4.4 cssselect-1.1.0 fake-useragent-0.1.11 parse-1.18.0 pyee-7.0.4 pyppeteer-0.2.2 pyquery-1.4.1 requests-html-0.10.0 tqdm-4.50.0 w3lib-1.22.0 websockets-8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Qp4ekcNUpb",
        "outputId": "99fec845-6762-43a5-e70a-8acb1908e91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import csv\n",
        "import pandas_datareader.data as web\n",
        "import pandas_datareader as pdr\n",
        "from pandas_datareader import data, wb\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.core.common.is_list_like = pd.api.types.is_list_like #For solving import pandas_datareader issue\n",
        "import os\n",
        "import random\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import urllib.request\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  from pandas.util.testing import assert_frame_equal\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhS568hr6yDL",
        "outputId": "f53efc12-97e9-4e25-9aec-f3df0676676a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wiki_url = 'https://en.wikipedia.org/wiki/NIFTY_50'             # get the NIFTY50 companies from wikipedia\n",
        "html1=urlopen(wiki_url)\n",
        "soup = BeautifulSoup(html1, 'html.parser')                # Extracting names from  HTML page\n",
        "nse50data1=\"\"          \n",
        "\n",
        "table = soup.find_all('table', class_=\"wikitable\")[0]         #retrieve all descendants that match  filter\n",
        "\n",
        "for record in table.findAll('tr'):\n",
        "    nse50data=\"\"\n",
        "    for data in record.findAll('td'):\n",
        "        nse50data=nse50data+\",\"+data.text  \n",
        "    nse50data1=nse50data1+\"\\n\"+nse50data[1:]\n",
        "\n",
        "print(nse50data1)\n",
        "f= open(\"nse50.txt\",\"w+\")\n",
        "\n",
        "f.write(nse50data1)\n",
        "f.close()\n",
        "headers = []\n",
        "for th in table.find(\"tr\").find_all(\"th\"):\n",
        "        headers.append(th.text.strip())\n",
        "rows = []\n",
        "for tr in table.find_all(\"tr\")[1:]:\n",
        "        cells = []\n",
        "        # grab all td tags in this table row\n",
        "        tds = tr.find_all(\"td\")\n",
        "        if len(tds) == 0:\n",
        "           \n",
        "            ths = tr.find_all(\"th\")\n",
        "            for th in ths:\n",
        "                cells.append(th.text.strip())\n",
        "        else:\n",
        "            # use regular td tags\n",
        "            for td in tds:\n",
        "                cells.append(td.text.strip())\n",
        "        rows.append(cells)\n",
        "d=pd.DataFrame(rows, columns=headers).to_csv(f\"table.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Adani Ports,ADANIPORTS.NS,Infrastructure\n",
            "\n",
            "Asian Paints,ASIANPAINT.NS,Consumer Goods\n",
            "\n",
            "Axis Bank,AXISBANK.NS,Banking\n",
            "\n",
            "Bajaj Auto,BAJAJ-AUTO.NS,Automobile\n",
            "\n",
            "Bajaj Finance,BAJFINANCE.NS,Financial Services\n",
            "\n",
            "Bajaj Finserv,BAJAJFINSV.NS,Financial Services\n",
            "\n",
            "Bharti Airtel,BHARTIARTL.NS,Telecommunication\n",
            "\n",
            "Bharti Infratel,INFRATEL.NS,Telecommunication\n",
            "\n",
            "Bharat Petroleum,BPCL.NS,Energy - Oil & Gas\n",
            "\n",
            "Britannia Industries,BRITANNIA.NS,Consumer Goods\n",
            "\n",
            "Cipla,CIPLA.NS,Pharmaceuticals\n",
            "\n",
            "Coal India,COALINDIA.NS,Energy & Mining\n",
            "\n",
            "Dr. Reddy's Laboratories,DRREDDY.NS,Pharmaceuticals\n",
            "\n",
            "Eicher Motors,EICHERMOT.NS,Automobile\n",
            "\n",
            "GAIL,GAIL.NS,Energy - Oil & Gas\n",
            "\n",
            "Grasim Industries,GRASIM.NS,Cement\n",
            "\n",
            "HCL Technologies,HCLTECH.NS,Information Technology\n",
            "\n",
            "HDFC,HDFC.NS,Financial Services\n",
            "\n",
            "HDFC Bank,HDFCBANK.NS,Banking\n",
            "\n",
            "HDFC Life,HDFCLIFE.NS,Insurance\n",
            "\n",
            "Hero MotoCorp,HEROMOTOCO.NS,Automobile\n",
            "\n",
            "Hindalco Industries,HINDALCO.NS,Metals\n",
            "\n",
            "Hindustan Unilever,HINDUNILVR.NS,Consumer Goods\n",
            "\n",
            "ICICI Bank,ICICIBANK.NS,Banking\n",
            "\n",
            "IndusInd Bank,INDUSINDBK.NS,Banking\n",
            "\n",
            "Infosys,INFY.NS,Information Technology\n",
            "\n",
            "Indian Oil Corporation,IOC.NS,Energy - Oil & Gas\n",
            "\n",
            "ITC Limited,ITC.NS,Consumer Goods\n",
            "\n",
            "JSW Steel,JSWSTEEL.NS,Metals\n",
            "\n",
            "Kotak Mahindra Bank,KOTAKBANK.NS,Banking\n",
            "\n",
            "Larsen & Toubro,LT.NS,Construction\n",
            "\n",
            "Mahindra & Mahindra,M&M.NS,Automobile\n",
            "\n",
            "Maruti Suzuki,MARUTI.NS,Automobile\n",
            "\n",
            "Nestlé India,NESTLEIND.NS,Consumer Goods\n",
            "\n",
            "NTPC,NTPC.NS,Energy - Power\n",
            "\n",
            "Oil and Natural Gas Corporation,ONGC.NS,Energy - Oil & Gas\n",
            "\n",
            "Power Grid Corporation of India,POWERGRID.NS,Energy - Power\n",
            "\n",
            "Reliance Industries,RELIANCE.NS,Energy - Oil & Gas\n",
            "\n",
            "State Bank of India,SBIN.NS,Banking\n",
            "\n",
            "Shree Cements,SHREECEM.NS,Cement\n",
            "\n",
            "Sun Pharmaceutical,SUNPHARMA.NS,Pharmaceuticals\n",
            "\n",
            "Tata Motors,TATAMOTORS.NS,Automobile\n",
            "\n",
            "Tata Steel,TATASTEEL.NS,Metals\n",
            "\n",
            "Tata Consultancy Services,TCS.NS,Information Technology\n",
            "\n",
            "Tech Mahindra,TECHM.NS,Information Technology\n",
            "\n",
            "Titan Company,TITAN.NS,Consumer Goods\n",
            "\n",
            "UltraTech Cement,ULTRACEMCO.NS,Cement\n",
            "\n",
            "United Phosphorus Limited,UPL.NS,Chemicals\n",
            "\n",
            "Wipro,WIPRO.NS,Information Technology\n",
            "\n",
            "Zee Entertainment Enterprises,ZEEL.NS,Media & Entertainment\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5sR1sqSK4RE",
        "outputId": "1e515eae-701f-4a72-cdb9-977d0c2ac0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "# Import list of stock names from NSE website\n",
        "#this is actually nse bhavcopy \n",
        "with requests.Session() as s:\n",
        "    download = s.get('https://www1.nseindia.com/products/content/sec_bhavdata_full.csv')\n",
        "    decoded_content = download.content.decode('utf-8')\n",
        "    cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
        "    df = pd.DataFrame(list(cr))\n",
        "    \n",
        "#View the top rows\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SYMBOL</td>\n",
              "      <td>SERIES</td>\n",
              "      <td>DATE1</td>\n",
              "      <td>PREV_CLOSE</td>\n",
              "      <td>OPEN_PRICE</td>\n",
              "      <td>HIGH_PRICE</td>\n",
              "      <td>LOW_PRICE</td>\n",
              "      <td>LAST_PRICE</td>\n",
              "      <td>CLOSE_PRICE</td>\n",
              "      <td>AVG_PRICE</td>\n",
              "      <td>TTL_TRD_QNTY</td>\n",
              "      <td>TURNOVER_LACS</td>\n",
              "      <td>NO_OF_TRADES</td>\n",
              "      <td>DELIV_QTY</td>\n",
              "      <td>DELIV_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20MICRONS</td>\n",
              "      <td>EQ</td>\n",
              "      <td>25-Sep-2020</td>\n",
              "      <td>26.20</td>\n",
              "      <td>26.80</td>\n",
              "      <td>30.20</td>\n",
              "      <td>26.80</td>\n",
              "      <td>29.50</td>\n",
              "      <td>28.45</td>\n",
              "      <td>28.10</td>\n",
              "      <td>54368</td>\n",
              "      <td>15.28</td>\n",
              "      <td>460</td>\n",
              "      <td>31523</td>\n",
              "      <td>57.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21STCENMGM</td>\n",
              "      <td>EQ</td>\n",
              "      <td>25-Sep-2020</td>\n",
              "      <td>10.20</td>\n",
              "      <td>10.00</td>\n",
              "      <td>10.30</td>\n",
              "      <td>10.00</td>\n",
              "      <td>10.30</td>\n",
              "      <td>10.15</td>\n",
              "      <td>10.09</td>\n",
              "      <td>3282</td>\n",
              "      <td>0.33</td>\n",
              "      <td>50</td>\n",
              "      <td>2536</td>\n",
              "      <td>77.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3IINFOTECH</td>\n",
              "      <td>EQ</td>\n",
              "      <td>25-Sep-2020</td>\n",
              "      <td>3.05</td>\n",
              "      <td>3.05</td>\n",
              "      <td>3.15</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.95</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.93</td>\n",
              "      <td>9668130</td>\n",
              "      <td>283.71</td>\n",
              "      <td>2745</td>\n",
              "      <td>4584932</td>\n",
              "      <td>47.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3MINDIA</td>\n",
              "      <td>EQ</td>\n",
              "      <td>25-Sep-2020</td>\n",
              "      <td>18367.45</td>\n",
              "      <td>18501.00</td>\n",
              "      <td>18657.00</td>\n",
              "      <td>18150.00</td>\n",
              "      <td>18190.00</td>\n",
              "      <td>18204.90</td>\n",
              "      <td>18244.86</td>\n",
              "      <td>5482</td>\n",
              "      <td>1000.18</td>\n",
              "      <td>3620</td>\n",
              "      <td>3534</td>\n",
              "      <td>64.47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0        1             2   ...             12          13          14\n",
              "0      SYMBOL   SERIES         DATE1  ...   NO_OF_TRADES   DELIV_QTY   DELIV_PER\n",
              "1   20MICRONS       EQ   25-Sep-2020  ...            460       31523       57.98\n",
              "2  21STCENMGM       EQ   25-Sep-2020  ...             50        2536       77.27\n",
              "3  3IINFOTECH       EQ   25-Sep-2020  ...           2745     4584932       47.42\n",
              "4     3MINDIA       EQ   25-Sep-2020  ...           3620        3534       64.47\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPJaD2dE7Csh"
      },
      "source": [
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMxVn2uw7GD9",
        "outputId": "6a5b7915-c9a0-4791-de53-30b7434c8fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "print(\"(CHOOSE THE TICKER FROM DATAFRAME MENTIONED ABOVE)\")\n",
        "print(\"\\nEnter the ticker\")\n",
        "stock_in=input()              #User input for the ticker\n",
        "def load_data(ticker=stock_in, n_steps=50, scale=True, shuffle=True, lookup_step=1, \n",
        "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    \"\"\"\n",
        "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
        "    Params:\n",
        "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc. You can add the ticker from list of niftyfifty companies shown above.\n",
        "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
        "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
        "        shuffle (bool): whether to shuffle the data, default is True\n",
        "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
        "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
        "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
        "    \"\"\"\n",
        "    # see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(ticker, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(ticker)\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = ticker\n",
        "    else:\n",
        "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
        "    # this will contain all the elements we want to return from this function\n",
        "    result = {}\n",
        "    # we will also return the original dataframe itself\n",
        "    result['df'] = df.copy()\n",
        "    # make sure that the passed feature_columns exist in the dataframe\n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "        # scale the data (prices) from 0 to 1\n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "        # add the MinMaxScaler instances to the result returned\n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "    # add the target column (label) by shifting by `lookup_step`\n",
        "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
        "    # last `lookup_step` columns contains NaN in future column\n",
        "    # get them before droping NaNs\n",
        "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "    # drop NaNs\n",
        "    df.dropna(inplace=True)\n",
        "    sequence_data = []\n",
        "    sequences = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_steps:\n",
        "            sequence_data.append([np.array(sequences), target])\n",
        "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
        "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
        "    # this last_sequence will be used to predict future stock prices not available in the dataset\n",
        "    last_sequence = list(sequences) + list(last_sequence)\n",
        "    last_sequence = np.array(last_sequence)\n",
        "    # add to result\n",
        "    result['last_sequence'] = last_sequence\n",
        "    # construct the X's and y's\n",
        "    X, y = [], []\n",
        "    for seq, target in sequence_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    # convert to numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # reshape X to fit the neural network\n",
        "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
        "    # split the dataset\n",
        "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
        "                                                                               test_size=test_size, shuffle=shuffle)\n",
        "    # return the result\n",
        "    return result"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(CHOOSE THE TICKER FROM DATAFRAME MENTIONED ABOVE)\n",
            "\n",
            "Enter the ticker\n",
            "SBIN.NS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgP9q_Cwidmo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}